{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1abf20c",
   "metadata": {
    "papermill": {
     "duration": 0.011208,
     "end_time": "2023-08-14T15:12:59.215343",
     "exception": false,
     "start_time": "2023-08-14T15:12:59.204135",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Kaggle - LLM Science Exam\n",
    "> Use LLMs to answer difficult science questions\n",
    "\n",
    "<img src=\"https://www.kaggle.com/competitions/54662/images/header\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85f2dd7",
   "metadata": {
    "papermill": {
     "duration": 0.010455,
     "end_time": "2023-08-14T15:12:59.236560",
     "exception": false,
     "start_time": "2023-08-14T15:12:59.226105",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🎯 | Motivation\n",
    "\n",
    "* In this notebook, we will demonstrate the usage of the multi-backend capabilities of `KerasCore` and `KerasNLP` for the **MultipleChoice** infernece."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abfbfbd",
   "metadata": {
    "papermill": {
     "duration": 0.010271,
     "end_time": "2023-08-14T15:12:59.257453",
     "exception": false,
     "start_time": "2023-08-14T15:12:59.247182",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 📌 | Updates\n",
    "* `v04` - DebertaV3Base, 2 folds\n",
    "* `v03` - DistilBertBase, 2 folds, fixed ShuffleOption\n",
    "* `v02` - DistilBertBase, 2 folds ShuffleOption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cb737f",
   "metadata": {
    "papermill": {
     "duration": 0.011366,
     "end_time": "2023-08-14T15:12:59.279193",
     "exception": false,
     "start_time": "2023-08-14T15:12:59.267827",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🛠 | Install Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "582631c9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-08-14T15:12:59.301893Z",
     "iopub.status.busy": "2023-08-14T15:12:59.301328Z",
     "iopub.status.idle": "2023-08-14T15:13:44.918062Z",
     "shell.execute_reply": "2023-08-14T15:13:44.916870Z"
    },
    "papermill": {
     "duration": 45.631094,
     "end_time": "2023-08-14T15:13:44.920695",
     "exception": false,
     "start_time": "2023-08-14T15:12:59.289601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/llm-science-exam-lib-ds/keras_core-0.1.4-py3-none-any.whl\r\n",
      "Installing collected packages: keras-core\r\n",
      "Successfully installed keras-core-0.1.4\r\n",
      "Processing /kaggle/input/llm-science-exam-lib-ds/keras_nlp-0.6.1-py3-none-any.whl\r\n",
      "Installing collected packages: keras-nlp\r\n",
      "Successfully installed keras-nlp-0.6.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install /kaggle/input/llm-science-exam-lib-ds/keras_core-0.1.4-py3-none-any.whl --no-deps\n",
    "!pip install /kaggle/input/llm-science-exam-lib-ds/keras_nlp-0.6.1-py3-none-any.whl --no-deps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aed7680",
   "metadata": {
    "papermill": {
     "duration": 0.011119,
     "end_time": "2023-08-14T15:13:44.943567",
     "exception": false,
     "start_time": "2023-08-14T15:13:44.932448",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 📚 | Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f23792e8",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-08-14T15:13:44.967850Z",
     "iopub.status.busy": "2023-08-14T15:13:44.966850Z",
     "iopub.status.idle": "2023-08-14T15:13:54.121707Z",
     "shell.execute_reply": "2023-08-14T15:13:54.120705Z"
    },
    "papermill": {
     "duration": 9.169693,
     "end_time": "2023-08-14T15:13:54.124234",
     "exception": false,
     "start_time": "2023-08-14T15:13:44.954541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using JAX backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # or \"tensorflow\" or \"torch\"\n",
    "\n",
    "import keras_nlp\n",
    "import keras_core as keras \n",
    "import keras_core.backend as K\n",
    "\n",
    "\n",
    "import jax\n",
    "import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# import tensorflow.keras.backend as K\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dec8f6",
   "metadata": {
    "papermill": {
     "duration": 0.011255,
     "end_time": "2023-08-14T15:13:54.147290",
     "exception": false,
     "start_time": "2023-08-14T15:13:54.136035",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Library Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2159144",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-08-14T15:13:54.172271Z",
     "iopub.status.busy": "2023-08-14T15:13:54.171032Z",
     "iopub.status.idle": "2023-08-14T15:13:54.177389Z",
     "shell.execute_reply": "2023-08-14T15:13:54.176502Z"
    },
    "papermill": {
     "duration": 0.020725,
     "end_time": "2023-08-14T15:13:54.179473",
     "exception": false,
     "start_time": "2023-08-14T15:13:54.158748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.12.0\n",
      "Keras: 0.1.4\n",
      "KerasNLP: 0.6.1\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow:\", tf.__version__)\n",
    "# print(\"JAX:\", jax.__version__)\n",
    "print(\"Keras:\", keras.__version__)\n",
    "print(\"KerasNLP:\", keras_nlp.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36cb93b",
   "metadata": {
    "papermill": {
     "duration": 0.011185,
     "end_time": "2023-08-14T15:13:54.201864",
     "exception": false,
     "start_time": "2023-08-14T15:13:54.190679",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ⚙️ | Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "686f1f36",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-08-14T15:13:54.227695Z",
     "iopub.status.busy": "2023-08-14T15:13:54.225959Z",
     "iopub.status.idle": "2023-08-14T15:13:54.233404Z",
     "shell.execute_reply": "2023-08-14T15:13:54.232468Z"
    },
    "papermill": {
     "duration": 0.022042,
     "end_time": "2023-08-14T15:13:54.235483",
     "exception": false,
     "start_time": "2023-08-14T15:13:54.213441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    verbose = 0  # Verbosity\n",
    "    device = 'TPU'  # Device\n",
    "    seed = 42  # Random seed\n",
    "    batch_size = 4  # Batch size\n",
    "    drop_remainder = True  # Drop incomplete batches\n",
    "    ckpt_dir = \"/kaggle/input/llm-science-exam-kerascore-kerasnlp-tpu-ds\"  # Name of pretrained models\n",
    "    sequence_length = 200  # Input sequence length\n",
    "    class_names = list(\"ABCDE\")  # Class names [A, B, C, D, E]\n",
    "    num_classes = len(class_names)  # Number of classes\n",
    "    class_labels = list(range(num_classes))  # Class labels [0, 1, 2, 3, 4]\n",
    "    label2name = dict(zip(class_labels, class_names))  # Label to class name mapping\n",
    "    name2label = {v: k for k, v in label2name.items()}  # Class name to label mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0b6e35",
   "metadata": {
    "papermill": {
     "duration": 0.01109,
     "end_time": "2023-08-14T15:13:54.257824",
     "exception": false,
     "start_time": "2023-08-14T15:13:54.246734",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ♻️ | Reproducibility \n",
    "Sets value for random seed to produce similar result in each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f41034e",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-08-14T15:13:54.281479Z",
     "iopub.status.busy": "2023-08-14T15:13:54.281172Z",
     "iopub.status.idle": "2023-08-14T15:13:54.285814Z",
     "shell.execute_reply": "2023-08-14T15:13:54.284860Z"
    },
    "papermill": {
     "duration": 0.019141,
     "end_time": "2023-08-14T15:13:54.288028",
     "exception": false,
     "start_time": "2023-08-14T15:13:54.268887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858bbb11",
   "metadata": {
    "papermill": {
     "duration": 0.010899,
     "end_time": "2023-08-14T15:13:54.310356",
     "exception": false,
     "start_time": "2023-08-14T15:13:54.299457",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 💾 | Hardware\n",
    "Following codes automatically detects hardware (TPU or GPU). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b68e1dc4",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-08-14T15:13:54.334967Z",
     "iopub.status.busy": "2023-08-14T15:13:54.333999Z",
     "iopub.status.idle": "2023-08-14T15:13:54.342574Z",
     "shell.execute_reply": "2023-08-14T15:13:54.341636Z"
    },
    "papermill": {
     "duration": 0.02305,
     "end_time": "2023-08-14T15:13:54.344643",
     "exception": false,
     "start_time": "2023-08-14T15:13:54.321593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    \"Detect and intializes GPU/TPU automatically\"\n",
    "    try:\n",
    "        # Connect to TPU\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect() \n",
    "        # Set TPU strategy\n",
    "        strategy = tf.distribute.TPUStrategy(tpu)\n",
    "        print(f'> Running on TPU', tpu.master(), end=' | ')\n",
    "        print('Num of TPUs: ', strategy.num_replicas_in_sync)\n",
    "        device=CFG.device\n",
    "    except:\n",
    "        # If TPU is not available, detect GPUs\n",
    "        gpus = tf.config.list_logical_devices('GPU')\n",
    "        ngpu = len(gpus)\n",
    "         # Check number of GPUs\n",
    "        if ngpu:\n",
    "            # Set GPU strategy\n",
    "            strategy = tf.distribute.MirroredStrategy(gpus) # single-GPU or multi-GPU\n",
    "            # Print GPU details\n",
    "            print(\"> Running on GPU\", end=' | ')\n",
    "            print(\"Num of GPUs: \", ngpu)\n",
    "            device='GPU'\n",
    "        else:\n",
    "            # If no GPUs are available, use CPU\n",
    "            print(\"> Running on CPU\")\n",
    "            strategy = tf.distribute.get_strategy()\n",
    "            device='CPU'\n",
    "    return strategy, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20b1545b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T15:13:54.369708Z",
     "iopub.status.busy": "2023-08-14T15:13:54.368738Z",
     "iopub.status.idle": "2023-08-14T15:13:57.064099Z",
     "shell.execute_reply": "2023-08-14T15:13:57.062728Z"
    },
    "papermill": {
     "duration": 2.7105,
     "end_time": "2023-08-14T15:13:57.066684",
     "exception": false,
     "start_time": "2023-08-14T15:13:54.356184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running on GPU | Num of GPUs:  1\n"
     ]
    }
   ],
   "source": [
    "# Initialize GPU/TPU/TPU-VM\n",
    "strategy, CFG.device = get_device()\n",
    "CFG.replicas = strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd86e38",
   "metadata": {
    "papermill": {
     "duration": 0.011019,
     "end_time": "2023-08-14T15:13:57.089332",
     "exception": false,
     "start_time": "2023-08-14T15:13:57.078313",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 📁 | Dataset Path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8756eb4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T15:13:57.114393Z",
     "iopub.status.busy": "2023-08-14T15:13:57.113452Z",
     "iopub.status.idle": "2023-08-14T15:13:57.118237Z",
     "shell.execute_reply": "2023-08-14T15:13:57.117172Z"
    },
    "papermill": {
     "duration": 0.019725,
     "end_time": "2023-08-14T15:13:57.120664",
     "exception": false,
     "start_time": "2023-08-14T15:13:57.100939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_PATH = '/kaggle/input/kaggle-llm-science-exam'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b130ffa",
   "metadata": {
    "papermill": {
     "duration": 0.010891,
     "end_time": "2023-08-14T15:13:57.143138",
     "exception": false,
     "start_time": "2023-08-14T15:13:57.132247",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 📖 | Meta Data \n",
    "* **train.csv** - a set of 200 questions with the answer column. Each question consists of a `prompt` (the question), 5 options labeled `A`, `B`, `C`, `D`, and `E`, and the correct answer labeled `answer` (this holds the label of the most correct answer, as defined by the generating LLM).\n",
    "* **test.csv** - similar to train.csv except it doesn't have `answer` column.  It has ~4000 questions that may be different is subject matter.\n",
    "* **sample_submission.csv** - is the test sample submission.\n",
    "    * `id`: number id of the question\n",
    "    * `prediction`: top 3 labels for your prediction. Once a correct label has been scored for an individual question in the test set, that label is no longer considered relevant for that question, and additional predictions of that label are skipped in the calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2836651e",
   "metadata": {
    "papermill": {
     "duration": 0.010923,
     "end_time": "2023-08-14T15:13:57.165467",
     "exception": false,
     "start_time": "2023-08-14T15:13:57.154544",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e27dbce5",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-08-14T15:13:57.190442Z",
     "iopub.status.busy": "2023-08-14T15:13:57.189482Z",
     "iopub.status.idle": "2023-08-14T15:13:57.226586Z",
     "shell.execute_reply": "2023-08-14T15:13:57.225164Z"
    },
    "papermill": {
     "duration": 0.052159,
     "end_time": "2023-08-14T15:13:57.229289",
     "exception": false,
     "start_time": "2023-08-14T15:13:57.177130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Test Data: 200\n",
      "# Sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>MOND is a theory that reduces the observed mis...</td>\n",
       "      <td>MOND is a theory that increases the discrepanc...</td>\n",
       "      <td>MOND is a theory that explains the missing bar...</td>\n",
       "      <td>MOND is a theory that reduces the discrepancy ...</td>\n",
       "      <td>MOND is a theory that eliminates the observed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Which of the following is an accurate definiti...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "      <td>Dynamic scaling refers to the non-evolution of...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "      <td>Dynamic scaling refers to the non-evolution of...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                             prompt  \\\n",
       "0   0  Which of the following statements accurately d...   \n",
       "1   1  Which of the following is an accurate definiti...   \n",
       "\n",
       "                                                   A  \\\n",
       "0  MOND is a theory that reduces the observed mis...   \n",
       "1  Dynamic scaling refers to the evolution of sel...   \n",
       "\n",
       "                                                   B  \\\n",
       "0  MOND is a theory that increases the discrepanc...   \n",
       "1  Dynamic scaling refers to the non-evolution of...   \n",
       "\n",
       "                                                   C  \\\n",
       "0  MOND is a theory that explains the missing bar...   \n",
       "1  Dynamic scaling refers to the evolution of sel...   \n",
       "\n",
       "                                                   D  \\\n",
       "0  MOND is a theory that reduces the discrepancy ...   \n",
       "1  Dynamic scaling refers to the non-evolution of...   \n",
       "\n",
       "                                                   E  \n",
       "0  MOND is a theory that eliminates the observed ...  \n",
       "1  Dynamic scaling refers to the evolution of sel...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df = pd.read_csv(f'{BASE_PATH}/test.csv')  # Read CSV file into a DataFrame\n",
    "\n",
    "# Display information about the train data\n",
    "print(\"# Test Data: {:,}\".format(len(test_df)))\n",
    "print(\"# Sample:\")\n",
    "display(test_df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09510814",
   "metadata": {
    "papermill": {
     "duration": 0.011595,
     "end_time": "2023-08-14T15:13:57.253145",
     "exception": false,
     "start_time": "2023-08-14T15:13:57.241550",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Contextualize Options\n",
    "\n",
    "Our approach entails furnishing the model with question and answer pairs, as opposed to employing a single question for all five options. In practice, this signifies that for the five options, we will supply the model with the same set of five questions combined with each respective answer choice (e.g., `(Q + A)`, `(Q + B)`, and so on). This analogy draws parallels to the practice of revisiting a question multiple times during an exam to promote a deeper understanding of the problem at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7a38be9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T15:13:57.279703Z",
     "iopub.status.busy": "2023-08-14T15:13:57.278028Z",
     "iopub.status.idle": "2023-08-14T15:13:57.284339Z",
     "shell.execute_reply": "2023-08-14T15:13:57.283471Z"
    },
    "papermill": {
     "duration": 0.021478,
     "end_time": "2023-08-14T15:13:57.286347",
     "exception": false,
     "start_time": "2023-08-14T15:13:57.264869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a function to create options based on the prompt and choices\n",
    "def make_options(row):\n",
    "    row['options'] = [f\"{row.prompt}\\n{row.A}\",  # Option A\n",
    "                      f\"{row.prompt}\\n{row.B}\",  # Option B\n",
    "                      f\"{row.prompt}\\n{row.C}\",  # Option C\n",
    "                      f\"{row.prompt}\\n{row.D}\",  # Option D\n",
    "                      f\"{row.prompt}\\n{row.E}\"]  # Option E\n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13a45fee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T15:13:57.310939Z",
     "iopub.status.busy": "2023-08-14T15:13:57.310603Z",
     "iopub.status.idle": "2023-08-14T15:13:57.474643Z",
     "shell.execute_reply": "2023-08-14T15:13:57.472551Z"
    },
    "papermill": {
     "duration": 0.178733,
     "end_time": "2023-08-14T15:13:57.476824",
     "exception": false,
     "start_time": "2023-08-14T15:13:57.298091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>options</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>MOND is a theory that reduces the observed mis...</td>\n",
       "      <td>MOND is a theory that increases the discrepanc...</td>\n",
       "      <td>MOND is a theory that explains the missing bar...</td>\n",
       "      <td>MOND is a theory that reduces the discrepancy ...</td>\n",
       "      <td>MOND is a theory that eliminates the observed ...</td>\n",
       "      <td>[Which of the following statements accurately ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Which of the following is an accurate definiti...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "      <td>Dynamic scaling refers to the non-evolution of...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "      <td>Dynamic scaling refers to the non-evolution of...</td>\n",
       "      <td>Dynamic scaling refers to the evolution of sel...</td>\n",
       "      <td>[Which of the following is an accurate definit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                             prompt  \\\n",
       "0   0  Which of the following statements accurately d...   \n",
       "1   1  Which of the following is an accurate definiti...   \n",
       "\n",
       "                                                   A  \\\n",
       "0  MOND is a theory that reduces the observed mis...   \n",
       "1  Dynamic scaling refers to the evolution of sel...   \n",
       "\n",
       "                                                   B  \\\n",
       "0  MOND is a theory that increases the discrepanc...   \n",
       "1  Dynamic scaling refers to the non-evolution of...   \n",
       "\n",
       "                                                   C  \\\n",
       "0  MOND is a theory that explains the missing bar...   \n",
       "1  Dynamic scaling refers to the evolution of sel...   \n",
       "\n",
       "                                                   D  \\\n",
       "0  MOND is a theory that reduces the discrepancy ...   \n",
       "1  Dynamic scaling refers to the non-evolution of...   \n",
       "\n",
       "                                                   E  \\\n",
       "0  MOND is a theory that eliminates the observed ...   \n",
       "1  Dynamic scaling refers to the evolution of sel...   \n",
       "\n",
       "                                             options  \n",
       "0  [Which of the following statements accurately ...  \n",
       "1  [Which of the following is an accurate definit...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = test_df.apply(make_options, axis=1)  # Apply the make_options function to each row in df\n",
    "test_df.head(2)  # Display the first 2 rows of df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82af04a1",
   "metadata": {
    "papermill": {
     "duration": 0.011804,
     "end_time": "2023-08-14T15:13:57.500680",
     "exception": false,
     "start_time": "2023-08-14T15:13:57.488876",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🍽️ | Preprocessing\n",
    "\n",
    "**What it does:** The preprocessor takes input strings and transforms them into a dictionary (`token_ids`, `padding_mask`) containing preprocessed tensors. This process starts with tokenization, where input strings are converted into sequences of token IDs.\n",
    "\n",
    "**Why it's important:** Initially, raw text data is complex and challenging for modeling due to its high dimensionality. By converting text into a compact set of tokens, such as transforming `\"The quick brown fox\"` into `[\"the\", \"qu\", \"##ick\", \"br\", \"##own\", \"fox\"]`, we simplify the data. Many models rely on special tokens and additional tensors to understand input. These tokens help divide input and identify padding, among other tasks. Making all sequences the same length through padding boosts computational efficiency, making subsequent steps smoother.\n",
    "\n",
    "Explore the following pages to access the available preprocessing and tokenizer layers in **KerasNLP**:\n",
    "- [Preprocessing](https://keras.io/api/keras_nlp/preprocessing_layers/)\n",
    "- [Tokenizers](https://keras.io/api/keras_nlp/tokenizers/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37d93325",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T15:13:57.526211Z",
     "iopub.status.busy": "2023-08-14T15:13:57.525856Z",
     "iopub.status.idle": "2023-08-14T15:13:58.242951Z",
     "shell.execute_reply": "2023-08-14T15:13:58.241919Z"
    },
    "papermill": {
     "duration": 0.732263,
     "end_time": "2023-08-14T15:13:58.245352",
     "exception": false,
     "start_time": "2023-08-14T15:13:57.513089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_path = '/kaggle/input/keras-nlp-deberta-v3-base-en-vocab-ds/vocab.spm'\n",
    "tokenizer= keras_nlp.models.DebertaV3Tokenizer(vocab_path)\n",
    "preprocessor= keras_nlp.models.DebertaV3Preprocessor(tokenizer, sequence_length=CFG.sequence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce7c717",
   "metadata": {
    "papermill": {
     "duration": 0.011583,
     "end_time": "2023-08-14T15:13:58.269468",
     "exception": false,
     "start_time": "2023-08-14T15:13:58.257885",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, let's examine what the output shape of the preprocessing layer looks like. The output shape of the layer can be represented as $(num\\_choices, sequence\\_length)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e81a48a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T15:13:58.295097Z",
     "iopub.status.busy": "2023-08-14T15:13:58.294743Z",
     "iopub.status.idle": "2023-08-14T15:14:02.135120Z",
     "shell.execute_reply": "2023-08-14T15:14:02.133906Z"
    },
    "papermill": {
     "duration": 3.855775,
     "end_time": "2023-08-14T15:14:02.137241",
     "exception": false,
     "start_time": "2023-08-14T15:13:58.281466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_ids : (5, 200)\n",
      "padding_mask : (5, 200)\n"
     ]
    }
   ],
   "source": [
    "outs = preprocessor(test_df.options.iloc[0])  # Process options for the first row\n",
    "\n",
    "# Display the shape of each processed output\n",
    "for k, v in outs.items():\n",
    "    print(k, \":\", v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acefe7d",
   "metadata": {
    "papermill": {
     "duration": 0.011924,
     "end_time": "2023-08-14T15:14:02.161257",
     "exception": false,
     "start_time": "2023-08-14T15:14:02.149333",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We'll use the `preprocessing_fn` function to transform each text option using the `dataset.map(preprocessing_fn)` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aea8e8b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T15:14:02.186614Z",
     "iopub.status.busy": "2023-08-14T15:14:02.185882Z",
     "iopub.status.idle": "2023-08-14T15:14:02.190884Z",
     "shell.execute_reply": "2023-08-14T15:14:02.189822Z"
    },
    "papermill": {
     "duration": 0.019786,
     "end_time": "2023-08-14T15:14:02.193021",
     "exception": false,
     "start_time": "2023-08-14T15:14:02.173235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_fn(text, label=None):\n",
    "    text = preprocessor(text)  # Preprocess text\n",
    "    return (text, label) if label is not None else text  # Return processed text and label if available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c0b175",
   "metadata": {
    "papermill": {
     "duration": 0.011827,
     "end_time": "2023-08-14T15:14:02.216971",
     "exception": false,
     "start_time": "2023-08-14T15:14:02.205144",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🍚 | DataLoader\n",
    "\n",
    "The code below sets up a robust data flow pipeline using `tf.data.Dataset` for data processing. Notable aspects of `tf.data` include its ability to simplify pipeline construction and represent components in sequences.\n",
    "\n",
    "To learn more about `tf.data`, refer to this [documentation](https://www.tensorflow.org/guide/data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e4fa21c",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-08-14T15:14:02.242279Z",
     "iopub.status.busy": "2023-08-14T15:14:02.241939Z",
     "iopub.status.idle": "2023-08-14T15:14:02.250163Z",
     "shell.execute_reply": "2023-08-14T15:14:02.249060Z"
    },
    "papermill": {
     "duration": 0.023632,
     "end_time": "2023-08-14T15:14:02.252440",
     "exception": false,
     "start_time": "2023-08-14T15:14:02.228808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_dataset(texts, labels=None, batch_size=32,\n",
    "                  cache=False, drop_remainder=True,\n",
    "                  augment=False, repeat=False, shuffle=1024):\n",
    "    AUTO = tf.data.AUTOTUNE  # AUTOTUNE option\n",
    "    slices = (texts,) if labels is None else (texts, keras.utils.to_categorical(labels, num_classes=5))  # Create slices\n",
    "    ds = tf.data.Dataset.from_tensor_slices(slices)  # Create dataset from slices\n",
    "    ds = ds.cache() if cache else ds  # Cache dataset if enabled\n",
    "    ds = ds.map(preprocess_fn, num_parallel_calls=AUTO)  # Map preprocessing function\n",
    "    ds = ds.repeat() if repeat else ds  # Repeat dataset if enabled\n",
    "    opt = tf.data.Options()  # Create dataset options\n",
    "    if shuffle: \n",
    "        ds = ds.shuffle(shuffle, seed=CFG.seed)  # Shuffle dataset if enabled\n",
    "        opt.experimental_deterministic = False\n",
    "    ds = ds.with_options(opt)  # Set dataset options\n",
    "    ds = ds.batch(batch_size, drop_remainder=drop_remainder)  # Batch dataset\n",
    "    ds = ds.prefetch(AUTO)  # Prefetch next batch\n",
    "    return ds  # Return the built dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2902b71a",
   "metadata": {
    "papermill": {
     "duration": 0.011733,
     "end_time": "2023-08-14T15:14:02.276121",
     "exception": false,
     "start_time": "2023-08-14T15:14:02.264388",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Fetch Train/test Dataset\n",
    "\n",
    "The function below generates the training and testation datasets for a given fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75fdd5ec",
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2023-08-14T15:14:02.301197Z",
     "iopub.status.busy": "2023-08-14T15:14:02.300858Z",
     "iopub.status.idle": "2023-08-14T15:14:02.306211Z",
     "shell.execute_reply": "2023-08-14T15:14:02.305294Z"
    },
    "papermill": {
     "duration": 0.02056,
     "end_time": "2023-08-14T15:14:02.308385",
     "exception": false,
     "start_time": "2023-08-14T15:14:02.287825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_test_dataset(test_df):\n",
    "    test_texts = test_df.options.tolist()  # Extract testation texts\n",
    "    \n",
    "    # Build testation dataset\n",
    "    test_ds = build_dataset(test_texts, labels=None,\n",
    "                             batch_size=min(CFG.batch_size*CFG.replicas, len(test_df)), cache=False,\n",
    "                             shuffle=False, drop_remainder=False, repeat=False)\n",
    "    \n",
    "    return test_ds  # Return datasets and dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4669d8",
   "metadata": {
    "papermill": {
     "duration": 0.011865,
     "end_time": "2023-08-14T15:14:02.332338",
     "exception": false,
     "start_time": "2023-08-14T15:14:02.320473",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🤖 | Modeling\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f36a5d",
   "metadata": {
    "_kg_hide-input": true,
    "papermill": {
     "duration": 0.011874,
     "end_time": "2023-08-14T15:14:02.356000",
     "exception": false,
     "start_time": "2023-08-14T15:14:02.344126",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Classifier for Multiple-Choice Tasks\n",
    "\n",
    "When dealing with multiple-choice questions, instead of giving the model the question and all options together `(Q + A + B + C ...)`, we provide the model with one option at a time along with the question. For instance, `(Q + A)`, `(Q + B)`, and so on. Once we have the prediction scores (logits) for all options, we combine them using the `Softmax` function to get the ultimate result. If we had given all options at once to the model, the text's length would increase, making it harder for the model to handle. The picture below illustrates this idea:\n",
    "\n",
    "![Model Diagram](https://pbs.twimg.com/media/F3NUju_a8AAS8Fq?format=png&name=large)\n",
    "\n",
    "<div align=\"center\"><b> Picture Credict: </b> <a href=\"https://twitter.com/johnowhitaker\"> @johnowhitaker </a> </div></div><br>\n",
    "\n",
    "From a coding perspective, remember that we use the same model for all five options, with shared weights. Despite the figure suggesting five separate models, they are, in fact, one model with shared weights. Another point to consider is the the input shapes of Classifier and MultipleChoice.\n",
    "\n",
    "* Input shape for **Multiple Choice**: $(batch\\_size, num\\_choices, seq\\_length)$\n",
    "* Input shape for **Classifier**: $(batch\\_size, seq\\_length)$\n",
    "\n",
    "Certainly, it's clear that we can't directly give the data for the multiple-choice task to the model because the input shapes don't match. To handle this, we'll use **slicing**. This means we'll separate the features of each option, like $feature_{(Q + A)}$ and $feature_{(Q + B)}$, and give them one by one to the NLP classifier. After we get the prediction scores $logits_{(Q + A)}$ and $logits_{(Q + B)}$ for all the options, we'll use the Softmax function, like $\\operatorname{Softmax}([logits_{(Q + A)}, logits_{(Q + B)}])$, to combine them. This final step helps us make the ultimate decision or choice.\n",
    "\n",
    "> Note that in the classifier, we set `num_classes=1` instead of `5`. This is because the classifier produces a single output for each option. When dealing with five options, these individual outputs are joined together and then processed through a softmax function to generate the final result, which has a dimension of `5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "914a40ca",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-08-14T15:14:02.381790Z",
     "iopub.status.busy": "2023-08-14T15:14:02.380989Z",
     "iopub.status.idle": "2023-08-14T15:14:02.392178Z",
     "shell.execute_reply": "2023-08-14T15:14:02.391322Z"
    },
    "papermill": {
     "duration": 0.026502,
     "end_time": "2023-08-14T15:14:02.394308",
     "exception": false,
     "start_time": "2023-08-14T15:14:02.367806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Selects one option from five\n",
    "class SelectOption(keras.layers.Layer):\n",
    "    def __init__(self, index, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.index = index\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Selects a specific slice from the inputs tensor\n",
    "        return inputs[:, self.index, :]\n",
    "    \n",
    "    def get_config(self):\n",
    "        # For serialize the model\n",
    "        base_config = super().get_config()\n",
    "        config = {\n",
    "            \"index\": self.index,\n",
    "        }\n",
    "        return {**base_config, **config}\n",
    "\n",
    "def build_model():\n",
    "    # Define input layers\n",
    "    inputs = {\n",
    "        \"token_ids\": keras.Input(shape=(5, None), dtype=tf.int32, name=\"token_ids\"),\n",
    "        \"padding_mask\": keras.Input(shape=(5, None), dtype=tf.int32, name=\"padding_mask\"),\n",
    "    }\n",
    "    # Create a DebertaV3Classifier model\n",
    "    classifier = keras_nlp.models.DebertaV3Classifier.from_preset(\n",
    "        CFG.preset,\n",
    "        preprocessor=None,\n",
    "        num_classes=1 # one output per one option, for five options total 5 outputs\n",
    "    )\n",
    "    logits = []\n",
    "    # Loop through each option (Q+A), (Q+B) etc and compute associted logits\n",
    "    for option_idx in range(5):\n",
    "        option = {k: SelectOption(option_idx, name=f\"{k}_{option_idx}\")(v) for k, v in inputs.items()}\n",
    "        logit = classifier(option)\n",
    "        logits.append(logit)\n",
    "        \n",
    "    # Compute final output\n",
    "    logits = keras.layers.Concatenate(axis=-1)(logits)\n",
    "    outputs = keras.layers.Softmax(axis=-1)(logits)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e513aaa",
   "metadata": {
    "papermill": {
     "duration": 0.011935,
     "end_time": "2023-08-14T15:14:02.417950",
     "exception": false,
     "start_time": "2023-08-14T15:14:02.406015",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Ckpt processing\n",
    "For some reason, `keras.models.load_model` requires write access as `/kaggle/input` doesn't have that access it throws error. Workaround is to simply copy the `ckpts` to other directory then load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9517d260",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T15:14:02.443382Z",
     "iopub.status.busy": "2023-08-14T15:14:02.443033Z",
     "iopub.status.idle": "2023-08-14T15:14:39.525515Z",
     "shell.execute_reply": "2023-08-14T15:14:39.524299Z"
    },
    "papermill": {
     "duration": 37.115564,
     "end_time": "2023-08-14T15:14:39.545356",
     "exception": false,
     "start_time": "2023-08-14T15:14:02.429792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total CKPT: 2\n"
     ]
    }
   ],
   "source": [
    "# Get the checkpoint directory and name\n",
    "ckpt_dir = CFG.ckpt_dir\n",
    "ckpt_name = ckpt_dir.split('/')[3]\n",
    "\n",
    "# Copy the checkpoints to a new directory in the /kaggle directory\n",
    "!cp -r {ckpt_dir} /kaggle/{ckpt_name}\n",
    "\n",
    "# List all the checkpoint paths in the new directory\n",
    "new_ckpt_dir = f\"/kaggle/{ckpt_name}\"\n",
    "ckpt_paths = glob(os.path.join(new_ckpt_dir, '*.keras'))\n",
    "\n",
    "print(\"Total CKPT:\", len(ckpt_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8560cc3",
   "metadata": {
    "papermill": {
     "duration": 0.012341,
     "end_time": "2023-08-14T15:14:39.573872",
     "exception": false,
     "start_time": "2023-08-14T15:14:39.561531",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🧪 | Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cf0107",
   "metadata": {
    "papermill": {
     "duration": 0.012128,
     "end_time": "2023-08-14T15:14:39.598096",
     "exception": false,
     "start_time": "2023-08-14T15:14:39.585968",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f8f04ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T15:14:39.624572Z",
     "iopub.status.busy": "2023-08-14T15:14:39.624168Z",
     "iopub.status.idle": "2023-08-14T15:23:05.165770Z",
     "shell.execute_reply": "2023-08-14T15:23:05.164566Z"
    },
    "papermill": {
     "duration": 505.559615,
     "end_time": "2023-08-14T15:23:05.170000",
     "exception": false,
     "start_time": "2023-08-14T15:14:39.610385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f212ccde5ad423c81dd984f4a69b0bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras_core/src/saving/serialization_lib.py:686: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
      "  instance.compile_from_config(compile_config)\n",
      "/opt/conda/lib/python3.10/site-packages/keras_core/src/backend/jax/numpy.py:103: UserWarning: Explicitly requested dtype int64 requested in arange is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jnp.arange(start, stop, step=step, dtype=dtype)\n",
      "/opt/conda/lib/python3.10/site-packages/keras_core/src/backend/jax/core.py:40: UserWarning: Explicitly requested dtype int64 requested in array is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return jnp.array(x, dtype=dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 954ms/step\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 978ms/step\n"
     ]
    }
   ],
   "source": [
    "# Initialize an array to store predictions for each fold\n",
    "fold_preds = np.zeros(shape=(len(test_df), 5), dtype='float32')\n",
    "\n",
    "# Iterate through each checkpoint path\n",
    "for ckpt_path in tqdm(ckpt_paths):\n",
    "    # Load the pre-trained model from the checkpoint\n",
    "    model = keras.models.load_model(\n",
    "        ckpt_path,\n",
    "        compile=False,\n",
    "        custom_objects={\"SelectOption\": SelectOption}  # Use the custom layer\n",
    "    )\n",
    "    \n",
    "    # Get the test dataset\n",
    "    test_ds = get_test_dataset(test_df)\n",
    "    \n",
    "    # Generate predictions using the model\n",
    "    preds = model.predict(\n",
    "        test_ds,\n",
    "        batch_size=min(CFG.batch_size * CFG.replicas * 2, len(test_df)),  # Set batch size\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Add predictions to fold_preds and average over checkpoints\n",
    "    fold_preds += preds / len(ckpt_paths)\n",
    "    \n",
    "    # Clean up by deleting the model and collecting garbage\n",
    "    del model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0199fb",
   "metadata": {
    "papermill": {
     "duration": 0.021,
     "end_time": "2023-08-14T15:23:05.213153",
     "exception": false,
     "start_time": "2023-08-14T15:23:05.192153",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Check Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ece8808",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-08-14T15:23:05.257527Z",
     "iopub.status.busy": "2023-08-14T15:23:05.256393Z",
     "iopub.status.idle": "2023-08-14T15:23:05.266062Z",
     "shell.execute_reply": "2023-08-14T15:23:05.264481Z"
    },
    "papermill": {
     "duration": 0.034034,
     "end_time": "2023-08-14T15:23:05.268241",
     "exception": false,
     "start_time": "2023-08-14T15:23:05.234207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Predictions\n",
      "\n",
      "❓ Question 1:\n",
      "Which of the following statements accurately describes the impact of Modified Newtonian Dynamics (MOND) on the observed \"missing baryonic mass\" discrepancy in galaxy clusters?\n",
      "\n",
      "🤖 Predicted Answer: B\n",
      "MOND is a theory that increases the discrepancy between the observed missing baryonic mass in galaxy clusters and the measured velocity dispersions from a factor of around 10 to a factor of about 20.\n",
      "\n",
      "------------------------------------------------------------------------------------------ \n",
      "\n",
      "❓ Question 2:\n",
      "Which of the following is an accurate definition of dynamic scaling in self-similar systems?\n",
      "\n",
      "🤖 Predicted Answer: D\n",
      "Dynamic scaling refers to the non-evolution of self-similar systems, where data obtained from snapshots at fixed times is dissimilar to the respective data taken from snapshots of any earlier or later time. This dissimilarity is tested by a certain time-independent stochastic variable y.\n",
      "\n",
      "------------------------------------------------------------------------------------------ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Format predictions and true answers\n",
    "pred_answers = np.array(list('ABCDE'))[np.argsort(-fold_preds)]\n",
    "\n",
    "# Check 5 Predictions\n",
    "print(\"# Predictions\\n\")\n",
    "for i in range(2):\n",
    "    row = test_df.iloc[i]\n",
    "    question  = row.prompt\n",
    "    pred_answer = pred_answers[i, 0]\n",
    "    print(f\"❓ Question {i+1}:\\n{question}\\n\")\n",
    "    print(f\"🤖 Predicted Answer: {pred_answer}\\n{row[pred_answer]}\\n\")\n",
    "    print(\"-\"*90, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cfa7e0",
   "metadata": {
    "papermill": {
     "duration": 0.020351,
     "end_time": "2023-08-14T15:23:05.308676",
     "exception": false,
     "start_time": "2023-08-14T15:23:05.288325",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 📮 | Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4bcabd5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T15:23:05.350918Z",
     "iopub.status.busy": "2023-08-14T15:23:05.350533Z",
     "iopub.status.idle": "2023-08-14T15:23:05.378726Z",
     "shell.execute_reply": "2023-08-14T15:23:05.374861Z"
    },
    "papermill": {
     "duration": 0.051706,
     "end_time": "2023-08-14T15:23:05.380850",
     "exception": false,
     "start_time": "2023-08-14T15:23:05.329144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>B D C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D C A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id prediction\n",
       "0   0      B D C\n",
       "1   1      D C A"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame to store the submission\n",
    "sub_df = test_df[[\"id\"]].copy()\n",
    "\n",
    "# Get the top 3 predicted answers\n",
    "top3_answers = pred_answers[:, :3]\n",
    "\n",
    "# Format the predicted answers as strings\n",
    "format_pred = [' '.join(x) for x in top3_answers]\n",
    "\n",
    "# Add the formatted predictions to the submission DataFrame\n",
    "sub_df[\"prediction\"] = format_pred\n",
    "\n",
    "# Save Submission\n",
    "sub_df.to_csv('submission.csv',index=False)\n",
    "\n",
    "# Display the first 2 rows of the submission DataFrame\n",
    "sub_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240eb7df",
   "metadata": {
    "papermill": {
     "duration": 0.020262,
     "end_time": "2023-08-14T15:23:05.422448",
     "exception": false,
     "start_time": "2023-08-14T15:23:05.402186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 620.083022,
   "end_time": "2023-08-14T15:23:08.798751",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-14T15:12:48.715729",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1cc6b43ab4bc430c800d98edb85f3575": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "34a4e2e09b884d5b894d2e66f49d788b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6b2fa50c3e7b471db90c799af5ea5361",
       "placeholder": "​",
       "style": "IPY_MODEL_3df638dea1d34db6a2b2eface0fdfff8",
       "value": "100%"
      }
     },
     "36a5372b808846c79e96d08d77e03079": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3df638dea1d34db6a2b2eface0fdfff8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3f212ccde5ad423c81dd984f4a69b0bd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_34a4e2e09b884d5b894d2e66f49d788b",
        "IPY_MODEL_ba4df2374fe84598ab17e691a3718d14",
        "IPY_MODEL_b8f26697cfed4004941d37a0e02449d2"
       ],
       "layout": "IPY_MODEL_fc116efb53e6469cbb5c255a76519edf"
      }
     },
     "516aabcbfd1545909d7277b195b4c119": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5ea862d6b26143a99c8a9d4904d28230": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6b2fa50c3e7b471db90c799af5ea5361": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b8f26697cfed4004941d37a0e02449d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_36a5372b808846c79e96d08d77e03079",
       "placeholder": "​",
       "style": "IPY_MODEL_5ea862d6b26143a99c8a9d4904d28230",
       "value": " 2/2 [08:25&lt;00:00, 252.59s/it]"
      }
     },
     "ba4df2374fe84598ab17e691a3718d14": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1cc6b43ab4bc430c800d98edb85f3575",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_516aabcbfd1545909d7277b195b4c119",
       "value": 2.0
      }
     },
     "fc116efb53e6469cbb5c255a76519edf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
